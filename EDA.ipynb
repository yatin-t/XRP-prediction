{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXBNsQbHVQVz"
      },
      "source": [
        "#Step 1 – Dataset Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KK2uS10EJdr"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download dataset (XRP-USD daily data)\n",
        "df = yf.download(\"XRP-USD\", start=\"2017-01-01\", end=\"2025-10-01\", progress=False)\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# Rename Adj Close\n",
        "df.rename(columns={'Adj Close': 'Adj_Close'}, inplace=True)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC3OqDpqVT9c"
      },
      "source": [
        "#Step 2 – Data Understanding & Preprocessing\n",
        "\n",
        "\n",
        "*   Clean the data (fix column names & duplicates)\n",
        "*   Add technical indicators (MA7, MA21, RSI, MACD, Bollinger Bands, etc.)\n",
        "* Check missing values, duplicates, and summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMKbLczXNvi4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# --- Fix MultiIndex columns (caused by Yahoo Finance) ---\n",
        "df.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
        "\n",
        "# --- Remove duplicates & sort by date ---\n",
        "df.drop_duplicates(subset=['Date'], inplace=True)\n",
        "df.sort_values('Date', inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# --- Check for missing values ---\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# --- Handle missing values (if any) ---\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# --- Add technical indicators ---\n",
        "df['MA7'] = df['Close'].rolling(7).mean()\n",
        "df['MA21'] = df['Close'].rolling(21).mean()\n",
        "df['MA50'] = df['Close'].rolling(50).mean()\n",
        "df['Return'] = df['Close'].pct_change()\n",
        "df['Volatility21'] = df['Return'].rolling(21).std()\n",
        "\n",
        "# RSI (Relative Strength Index)\n",
        "delta = df['Close'].diff()\n",
        "gain = np.where(delta > 0, delta, 0)\n",
        "loss = np.where(delta < 0, -delta, 0)\n",
        "avg_gain = pd.Series(gain).rolling(14).mean()\n",
        "avg_loss = pd.Series(loss).rolling(14).mean()\n",
        "rs = avg_gain / avg_loss\n",
        "df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "# MACD (12-day EMA - 26-day EMA)\n",
        "ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "df['MACD'] = ema12 - ema26\n",
        "df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "# Bollinger Bands\n",
        "df['BB_upper'] = df['MA21'] + 2*df['Close'].rolling(21).std()\n",
        "df['BB_lower'] = df['MA21'] - 2*df['Close'].rolling(21).std()\n",
        "\n",
        "# --- Final clean-up ---\n",
        "df.fillna(method='bfill', inplace=True)\n",
        "\n",
        "print(\"✅ Data cleaned and enriched with technical indicators!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvVME36qVzcW"
      },
      "source": [
        "#Step 3 – Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnXXdjXJOcRB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "# 1️⃣ Closing Price Trend\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df['Date'], df['Close'], label='XRP Close Price', color='blue')\n",
        "plt.title('XRP Closing Price Over Time')\n",
        "plt.xlabel('Date'); plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Insight 1️⃣: Shows XRP price fluctuations over years — clear volatility and long-term trends visible.\")\n",
        "\n",
        "# 2️⃣ Correlation Heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df[['Close','High','Low','Open','Volume','RSI','MACD','MA21','Volatility21']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "print(\"Insight 2️⃣: Close, High, Low, Open are strongly correlated (>0.9). Volume and RSI show weaker relationships, indicating market momentum effects.\")\n",
        "\n",
        "# 3️⃣ Distribution of Daily Returns\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['Return'], bins=50, kde=True, color='purple')\n",
        "plt.title('Distribution of Daily Returns')\n",
        "plt.xlabel('Daily Return')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "print(\"Insight 3️⃣: Daily returns are mostly centered near zero, with a few extreme outliers — highlighting XRP's high volatility nature.\")\n",
        "\n",
        "# 4️⃣ RSI vs Price (Overbought/Oversold Analysis)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df['Date'], df['RSI'], label='RSI', color='orange')\n",
        "plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')\n",
        "plt.axhline(30, color='green', linestyle='--', label='Oversold (30)')\n",
        "plt.title('Relative Strength Index (RSI) Over Time')\n",
        "plt.xlabel('Date'); plt.ylabel('RSI Value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Insight 4️⃣: RSI fluctuates between 30–70; spikes above 70 indicate overbought zones followed by price corrections.\")\n",
        "\n",
        "# 5️⃣ Bollinger Bands (Volatility Analysis)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df['Date'], df['Close'], label='Close Price', color='blue')\n",
        "plt.plot(df['Date'], df['BB_upper'], label='Upper Band', color='red', linestyle='--')\n",
        "plt.plot(df['Date'], df['BB_lower'], label='Lower Band', color='green', linestyle='--')\n",
        "plt.title('Bollinger Bands – Price Volatility')\n",
        "plt.xlabel('Date'); plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Insight 5️⃣: When price touches or crosses the upper/lower Bollinger Bands, it indicates strong market volatility and potential reversals.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RgPlorVV64m"
      },
      "source": [
        "#Step 4 – Model Building: LSTM for XRP Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_0U9_0UWAyR"
      },
      "source": [
        "Step 4.1 – Data Preparation for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQYKU7_0OkWy"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Select features for model\n",
        "features = ['Close','High','Low','Open','Volume','MA7','MA21','MA50','RSI','MACD','Volatility21']\n",
        "data = df[features].values\n",
        "\n",
        "# Normalize\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Sequence creation (60 days history → next day prediction)\n",
        "def create_sequences(data, seq_length=60):\n",
        "    X, y = [], []\n",
        "    for i in range(seq_length, len(data)):\n",
        "        X.append(data[i-seq_length:i])\n",
        "        y.append(data[i, 0])  # Predict next day's Close\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60)\n",
        "\n",
        "# Split\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "print(\"✅ Sequences created successfully!\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR8rAduwWFUX"
      },
      "source": [
        "Step 4.2 – Build and Train the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjxQDRH2OrPA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fOAOqNCWJBC"
      },
      "source": [
        "#Step 5 – Model Evaluation & Visualization\n",
        "\n",
        "We’ll visualize:\n",
        "* Loss vs Epoch (training curve)\n",
        "\n",
        "* Actual vs Predicted price (performance plot)\n",
        "\n",
        "* Error distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwO-pr41PDO1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predicted = model.predict(X_test)\n",
        "predicted_prices = scaler.inverse_transform(np.concatenate([predicted, np.zeros((len(predicted), data.shape[1]-1))], axis=1))[:,0]\n",
        "actual_prices = scaler.inverse_transform(np.concatenate([y_test.reshape(-1,1), np.zeros((len(y_test), data.shape[1]-1))], axis=1))[:,0]\n",
        "\n",
        "# Compare visually\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(actual_prices, label='Actual Price')\n",
        "plt.plot(predicted_prices, label='Predicted Price')\n",
        "plt.title('XRP Price Prediction (LSTM)')\n",
        "plt.xlabel('Days'); plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss vs Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "errors = actual_prices - predicted_prices\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(errors, bins=30, kde=True)\n",
        "plt.title('Prediction Error Distribution')\n",
        "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
        "plt.show()\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1} → Actual: {actual_prices[i]:.4f}, Predicted: {predicted_prices[i]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaDvsYF4Wa6W"
      },
      "source": [
        "#Step 6 – Conclusion & Future Scope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27glVA71WeYj"
      },
      "source": [
        "Conclusion:\n",
        "\n",
        "The project applied Exploratory Data Analysis (EDA) and Deep Learning (LSTM) for predicting the future price of XRP cryptocurrency using real-world historical data (2017–2025).\n",
        "The dataset contained six core features — Open, High, Low, Close, Volume, Date — and was enhanced with ten derived technical indicators such as moving averages (MA7, MA21, MA50), RSI, MACD, Volatility, and Bollinger Bands to provide stronger predictive signals.\n",
        "\n",
        "After preprocessing and scaling, the data was used to train an LSTM-based time series model that captures sequential patterns across 60 previous trading days.\n",
        "The model achieved low validation loss (≈ 5×10⁻⁵) and visually demonstrated strong alignment between predicted and actual price trends.\n",
        "\n",
        "Key Learnings\n",
        "\n",
        "* EDA revealed clear volatility cycles and price momentum patterns.\n",
        "\n",
        "* RSI and MACD proved influential in detecting uptrends and corrections.\n",
        "\n",
        "* LSTM networks effectively captured temporal dependencies compared to linear models.\n",
        "\n",
        "* Proper normalization and feature engineering significantly improved convergence.\n",
        "\n",
        "\n",
        "Challenges Faced\n",
        "\n",
        "* High variance in crypto data caused early overfitting without dropout layers.\n",
        "\n",
        "* Scaling back the predictions required careful inverse transformation handling.\n",
        "\n",
        "* Handling missing and noisy data before 2017 was critical to avoid distortions.\n",
        "\n",
        "Future Scope\n",
        "\n",
        "* Use Transformer-based architectures (e.g., Temporal Fusion Transformer or BERT for time series) to improve long-term forecasting.\n",
        "\n",
        "* Integrate sentiment analysis from Twitter or Reddit to account for social signals.\n",
        "\n",
        "* Build a real-time dashboard using Streamlit or Power BI for live prediction updates.\n",
        "\n",
        "* Incorporate multiple cryptocurrencies (BTC, ETH, ADA) for multi-asset modeling."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
